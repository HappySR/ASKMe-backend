# **ASKMe Backend** ğŸ§ ğŸ’¬  

This is the backend service for **ASKMe**, a powerful AI-driven conversational assistant that supports **text, documents, audio, and video processing**. It integrates **Google Gemini AI**, **LibreTranslate**, and **Whisper** to provide intelligent responses, translations, and transcriptions.

## ğŸš€ Features  
- âœ… **Text Processing**: Understands and responds to text-based queries.  
- ğŸ“„ **Document Analysis**: Extracts and processes text from **PDF, DOCX, and TXT** files.  
- ğŸ™ **Audio Processing**: Transcribes and analyzes audio files using **Whisper AI**.  
- ğŸ¥ **Video Processing**: Extracts audio from video files, transcribes it, and processes it via **Gemini AI**.  
- ğŸŒ **Translation Support**: Detects language and translates responses using **LibreTranslate**.  
- ğŸ”¥ **FastAPI-based API**: A robust, asynchronous backend built with **FastAPI**.  

---

## ğŸ“Œ **Installation**  

### 1ï¸âƒ£ **Clone the Repository**  
```bash
git clone https://github.com/YOUR_USERNAME/askme-backend.git
cd askme-backend
```

### 2ï¸âƒ£ Set Up the Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Create a .env File

Create a .env file in the root directory and add the following:

```bash
GEMINI_API_KEY="YOUR_GEMINI_API_KEY"
LIBRETRANSLATE_URL="http://localhost:5000" # Example LibreTranslate instance
```

## ğŸ›  Usage
### 1ï¸âƒ£ Run the Server

```bash
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

This starts the FastAPI server on http://127.0.0.1:8000/.
### 2ï¸âƒ£ API Endpoints
#### ğŸ“Œ Process Text Input

```bash
POST /api/process_text
```

    â€¢ Description: Processes a text query and returns a response.
    â€¢ Request Body:

```bash
{
  "text": "What is the capital of France?",
  "target_language": "fr"
}
```

â€¢ Response:

```bash
    {
      "response": "La capitale de la France est Paris."
    }
```

#### ğŸ“Œ Process Document (PDF, DOCX, TXT)

```bash
POST /api/process_document
```

    â€¢ Description: Extracts and processes text from a document.
    â€¢ Request Example (Using cURL):

```bash
curl -X 'POST' 'http://127.0.0.1:8000/api/process_document' \
  -H 'accept: application/json' \
  -H 'Content-Type: multipart/form-data' \
  -F 'file=@document.pdf' \
  -F 'prompt=Summarize this document' \
  -F 'target_language=en'
```

â€¢ Response Example:

```bash
    {
      "response": "This document discusses the effects of climate change on global agriculture."
    }
```

## ğŸ™ Process Audio (MP3, WAV, FLAC)

```bash
POST /api/process_audio
```

    â€¢ Description: Transcribes an audio file and sends it to Gemini AI.
    â€¢ Request Example:

```bash
curl -X 'POST' 'http://127.0.0.1:8000/api/process_audio' \
  -H 'accept: application/json' \
  -H 'Content-Type: multipart/form-data' \
  -F 'file=@speech.wav' \
  -F 'prompt=Summarize this speech'
```

â€¢ Response Example:

```bash
    {
      "response": "The speaker discusses the importance of AI in modern education."
    }
```

## ğŸ¥ Process Video (MP4, MOV, AVI)

```bash
POST /api/process_video
```

    â€¢ Description: Extracts audio from a video, transcribes it, and processes it via Gemini AI.
    â€¢ Request Example:

```bash
curl -X 'POST' 'http://127.0.0.1:8000/api/process_video' \
  -H 'accept: application/json' \
  -H 'Content-Type: multipart/form-data' \
  -F 'file=@lecture.mp4' \
  -F 'prompt=Summarize the key points'
```

â€¢ Response Example:

```bash
    {
      "response": "The lecture explains Newton's three laws of motion with examples."
    }
```

## âš™ï¸ Project Structure

```bash
askme-backend/
â”‚â”€â”€ agents/
â”‚   â”œâ”€â”€ audio_agent.py        # Handles audio processing
â”‚   â”œâ”€â”€ document_agent.py     # Handles document analysis
â”‚   â”œâ”€â”€ video_agent.py        # Handles video processing
â”‚
â”‚â”€â”€ services/
â”‚   â”œâ”€â”€ gemini_service.py     # Manages communication with Gemini AI
â”‚   â”œâ”€â”€ whisper_service.py    # Transcribes speech using Whisper
â”‚   â”œâ”€â”€ libretranslate_service.py  # Handles translation
â”‚
â”‚â”€â”€ app.py                    # Main FastAPI application
â”‚â”€â”€ requirements.txt           # Python dependencies
â”‚â”€â”€ .env                       # API keys & environment variables
â”‚â”€â”€ README.md                  # This file
```

## ğŸ¯ Future Improvements

    ğŸ† Support for more file types (PPTX, EPUB, etc.)
    ğŸ”¥ Real-time transcription for live audio/video streams
    ğŸŒ Improved multilingual support
    âš¡ Better caching for faster responses

## ğŸ¤ Contributing

We welcome contributions! ğŸ‰
To contribute:

    Fork the repository
    Create a new branch: git checkout -b feature-name
    Make your changes and commit: git commit -m "Added new feature"
    Push to your branch: git push origin feature-name
    Create a Pull Request

## ğŸ“œ License

This project is licensed under the MIT License.
ğŸ›  Developed By

ğŸ’¡ Subhajit Roy
ğŸš€ Connect with me: [GitHub](https://github.com/YOUR_GITHUB_USERNAME) | [LinkedIn](https://www.linkedin.com/in/YOUR_LINKEDIN_USERNAME)